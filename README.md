<h1 align="center">FlexiProxy</h1>
<p align="center">
  <strong>一个简单灵活的 OpenAI-Compatible API 代理网关</strong>
  <br/>
  <strong>A powerful and flexible OpenAI-Compatible API Proxy Gateway</strong>
</p>

<div align="center">

[![GitHub](https://img.shields.io/badge/FlexiProxyGateway-0.0.1-blue?logo=github)](https://github.com/SanChai20/Flexi-Proxy-Gateway)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE.md)
[![Website](https://img.shields.io/badge/Website-Active-orange?logo=vercel)](https://flexiproxy.com)

</div>

<p align="center">
  <a href="#-中文">中文</a> •
  <a href="#-english">English</a>
</p>

---

## 中文

### 概述

FlexiProxy 提供 OpenAI 兼容的代理服务，支持通过统一接口调用 100 多种大语言模型。它允许用户在使用现有 LLM 客户端（如Claude Code 等）时，灵活地切换后端服务提供商，有效解决特定区域模型服务昂贵或不可用的问题。同样对于只持有一套OpenAI-Compatible API凭证的用户来说可以借此代理服务体验不同的 LLM 客户端。

### 核心价值

1. 通用服务 - 一个LLM供应商支持任意客户端接入
2. 灵活切换 - 一个客户端可自由选择并切换LLM服务

### 主要特性

-   **🌍 区域灵活性**: 轻松绕过地域限制，选择更具性价比的模型服务
-   **⚙️ 简单配置**: 通过直观的 Web 界面轻松创建和管理代理服务
-   **🔒 密钥安全**: 您的源 API Key 仅用于服务请求转发，我们会安全处理。授权的 API Key 由您自主管理
-   **🤝 广泛兼容**: 支持任何提供 OpenAI-Compatible API 的服务提供商（如 DeepSeek, DeepInfra, Qwen, xAI Grok 等）

### 快速开始

> **重要提示**：FlexiProxy 作为中间层，本身不提供 LLM 服务。

详情请参考网站[说明文档](https://flexiproxy.com/documentation)

### 联系开发者

如果您在使用过程中遇到任何问题或有建议，欢迎通过以下方式联系开发者：
-   [创建 GitHub Issue](https://github.com/SanChai20/Flexi-Proxy/issues)
-   [网站上联系我们](https://flexiproxy.com/contact)

---

## English

### Overview

FlexiProxy provides an OpenAI-compatible proxy service that supports calling over 100 large language models through a unified interface. It allows users to flexibly switch backend service providers when using existing LLM clients (such as Claude Code, etc.), effectively solving the issues of expensive or unavailable model services in specific regions. Similarly, for users who only hold one set of OpenAI-Compatible API credentials, they can experience different LLM clients through this proxy service.

### Core Values

1. Universal Service - One LLM provider supports access from any client
2. Flexible Switching - One client can freely select and switch LLM services

### Key Features

-   **🌍 Regional Flexibility**: Easily bypass regional restrictions and select more cost-effective model services
-   **⚙️ Simple Configuration**: Easily create and manage proxy services through an intuitive web interface
-   **🔒 Key Security**: Your source API Key is only used for service request forwarding; we handle it securely. Authorized API Keys are managed by you
-   **🤝 Broad Compatibility**: Supports any service provider that offers OpenAI-Compatible APIs (such as DeepSeek, DeepInfra, Qwen, xAI Grok, etc.)

### Quick Start

> Important Note: FlexiProxy acts as an intermediary layer and does not provide LLM services itself.

See more details, please refer to [website](https://flexiproxy.com/documentation)

### Contact the Developer

If you encounter any issues or have suggestions during use, feel free to contact the developer via:
-   [Create a GitHub Issue](https://github.com/SanChai20/Flexi-Proxy/issues)
-   [Contact from website](https://flexiproxy.com/contact)

---

*最后更新 | Last Updated: 2025年9月27日 | September 27, 2025*